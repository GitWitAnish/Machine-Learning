{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70bb7b21-43db-43fa-8bf8-ffbd04891627",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b45122-30f5-44ad-a030-18f56855b79e",
   "metadata": {},
   "source": [
    "### Logistic regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48aa41f8-8ddf-4aa0-9196-5bfcb9ff9662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ 0.91260242 -0.20690417] Bias: -1.1195065937669515\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_regression(X, y, alpha=0.01, iterations=1000):\n",
    "    m, n = X.shape\n",
    "    w = np.zeros(n)\n",
    "    b = 0\n",
    "\n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, w) + b\n",
    "        h = sigmoid(z)\n",
    "        dw = (1/m) * np.dot(X.T, (h - y))\n",
    "        db = (1/m) * np.sum(h - y)\n",
    "        w -= alpha * dw\n",
    "        b -= alpha * db\n",
    "\n",
    "    return w, b\n",
    "\n",
    "# Example\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "w, b = logistic_regression(X, y)\n",
    "print(\"Weights:\", w, \"Bias:\", b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a391e20f-561b-492a-b4df-bf165acb3c7e",
   "metadata": {},
   "source": [
    "### Using scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c433d22-3713-40e4-bddc-00380a8aaf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [1 0]\n",
      "Prediction probabilities:\n",
      " [[4.43353861e-01 5.56646139e-01]\n",
      " [9.99836483e-01 1.63516634e-04]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "X = np.array([[2.5, 21], [5.1, 47], [3.2, 31], [8.5, 75],\n",
    "              [3.5, 30], [1.5, 20], [9.2, 88], [5.5, 60]])\n",
    "y = np.array([0, 0, 0, 1, 0, 0, 1, 1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "print(\"Predicted classes:\", y_pred)\n",
    "print(\"Prediction probabilities:\\n\", y_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4d8f7e-14a7-4f78-a78c-15c2b257fdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[1 1]\n",
      " [0 0]]\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.50      0.25      0.33         2\n",
      "weighted avg       1.00      0.50      0.67         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation_metrices\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911234bd-885c-4a76-824a-404d7ee781ba",
   "metadata": {},
   "source": [
    "## One-vs-Rest (OvR) Logistic Regression\n",
    "\n",
    "This is when you have multiple classes (more than two) like cat, dog, rabbit\n",
    "but logistic regression can only handle binary output.\n",
    "So we make multiple binary models, one per class:\n",
    "\n",
    "Model 1: cat vs rest\n",
    "\n",
    "Model 2: dog vs rest\n",
    "\n",
    "Model 3: rabbit vs rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c33eb-9080-4334-968e-0ee48ecc1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class='ovr', max_iter=200)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c44355",
   "metadata": {},
   "source": [
    "remember multi class and mutiple variable is different thing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
